---
title: "Recommendations for an intelligent diet"
author: "Keana Richards, Jeesung Ahn, Tonah Salas Ortiz"
date: ' '
output:
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '4'
bibliography: library.bib
---

```{r setup, include=FALSE}
options(scipen = 0, digits = 3, tibble.print_max = 50) 

knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning = F)

if(!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, here, glmnet, car, data.table, summarytools, corrplot, GGally, varhandle, gtsummary, pROC, stargazer, sjPlot, report,tm,SnowballC,wordcloud,RColorBrewer, imputeTS, clValid, cluster, factoextra, fpc) 


plot_aes = theme_minimal() +
  theme(legend.position = "top",
        text = element_text(size = 15, family = "Futura Medium"),
        axis.text = element_text(color = "black"),
        axis.line = element_line(colour = "black"),
        axis.ticks.y = element_blank())
```


```{r include=F}

source(here("source", "primary_analyses.R"))
```

# Executive Summary {#executive-summary}

Many countries around the world provide nationwide dietary guidelines to the public and require nutrition labels on food products to help people make informed choices about foods and drinks they consume. Every individual, however, has different nutrition needs and preferences according to their age, sex, ethnicity, height, weight, and physical activity level, among many other factors. Therefore, people may benefit from more personalized dietary recommendations. Our goal is to provide the basis for an algorithm that recommends foods a person should consume based on their nutrition needs. To this end, we compared different approaches to grouping foods based on their nutrient profiles (i.e., spectrum clustering vs. k-means clustering). As expected, spectrum clustering provides better clustering, so we explore the clusters created through spectrum clustering further. Finally, we demonstrate how others can use our data-driven food groupings to meet their dietary needs. 

# Introduction {#introduction} 

## Importance of nutrition in affecting everyday life 

One of the most important determinants of one's health is their diet: the nutrients we consume can affect a range of our health outcomes, from cardiovascular disease [@ShantaRetelny2008] and obesity [@Popkin2004] to learning and general brain function [@Dani2005]. Unfortunately, many people around the world are not consuming enough of the nutrients that promote their health, and instead their diet consists mainly of too much of the nutrients that directly hurt their health [@Popkin2004]. In many cases, across the United States and similarly wealthy countries, people are simply overwhelmed by the overabundance of food options available to them, so they end up choosing whatever is easiest and/or fastest to consume, leading to the popularity of "fast food". Given the importance of choosing the nutrients in our diet, helping people narrow down the range of options for foods by creating categories of foods that are similar will likely free up time to make better diet decisions.  

## Problem with current food groupings 

Although foods are already grouped together in different categories in many nutrition datasets, the means by which these food groupings are created is unclear, so food items in a certain group may not necessarily have the same nutrient profile. A new interpretation of food groupings can change the way diets are currently made - helping people make more “intelligent” diet decisions. More specifically, the results of this study can be used to find the list of foods that have the best combination of nutrients based on a person's dietary needs.

# Study goals

In the current project, we aim to provide the basis for an algorithm that recommends foods a person should consume based on their nutrition needs. In more concrete terms, we wanted to identify clusters of foods that have the highest intra-group similarity and lowest inter-group similarity based on their nutrient profile. 

# Methods {#methods}

## Exploratory data analysis {#eda} 

Our dataset originates from the most recent version of the [Canadian Nutrient File](https://www.canada.ca/en/health-canada/services/food-nutrition/healthy-eating/nutrient-data/canadian-nutrient-file-2015-download-files.html) (updated in 2015), provided on the Canadian government site. The database contains average values for nutrients in foods available in Canada, with much of the data coming from the USDA National Nutrient Database for Standard Reference. These averages are based on the generic versions of a food, unless there is a brand specifically included in the database. This is a bilingual dataset with food names, descriptions, and background information that are in both French and English. This version of the database was created to update nutrient values for foods that are the largest contributors of sodium to the diet, since one of the major goals of manufacturers is to reduce sodium content of foods. To this end, the database assesses more than `r nrow(wide_data)` unique foods, ranging from foods such as `r wide_data %>% select(FoodDescription) %>% slice(1)` to `r wide_data %>% select(FoodDescription) %>% slice(174)`, and provides the average nutrient levels per 100 grams. 

The original data came as a set of separate datasets that had columns with identifiers (e.g., `FoodID`) to link them, so we then merged the datasets based on the unique identifiers and selected the main variables of interest: the food labels and the nutrient profile associated with a given food label. With this subsetted version of the data, we ran exploratory data analyses.  

First, we noticed that some of the nutrients included are subcomponents of other nutrients. For instance, there is a total sugars column that is a sum of several other columns in the data. In other cases, there are columns that are essentially different ways of measuring the same nutrient. So for example, there are two metrics for food energy (i.e., kilocalories and kilojoules), where one kilocalorie is equal to 4.184 kilojoules. We decided to leave these variables as they were, since we expected the methods used in our analyses to be able to essentially ignore these redundancies. 

Also, it is worth noting that there are many values that are missing. For instance, only `r sum(is.na(wide_data %>% select(BIOTIN)))/nrow(wide_data)`% of the rows have values for biotin (see [Missing values in clean dataset section](#missing-vals-clean)). To be able to run our target analyses (which requires a dataset with only nonmissing data), we needed to remove the missing values. We explored two different options for removing missing variables to see whether they would affect the results: mean imputation (i.e., inserted the mean of a column into any rows in that column that are missing) for all variables or first removing variables with more than 50% of missing values and then using mean imputation on the survived variables. We found that the options produced similar results across our different options for mean imputation, so we used the version of the dataset where we used mean imputation for all variables in all subsequent analyses. See [the appendix](#clean-data-summary) for a full summary of the variables in the cleaned dataset after using mean imputation for all variables. 

## Main analyses {#analyses}

Since our goal is to identify the *best* algorithm for grouping foods that will help a person plan out their meals to best suit their needs, we compared different approaches to grouping the foods based on their nutrient profiles. That is, we compared different methods to make sure foods are as similar as possible in terms of their nutrient profile (that is, we wanted to maximize in-group similarity), while also making sure foods assigned to different groups have very different nutrient profiles (in other words, minimize out-group similarity). The code, database, and final write up associated with this project is publicly available [here](https://www.tinyurl.com/4x43u439). 

The first option we explored to achieve this goal was using k-means clustering on the dataset. K-means clustering is a commonly used unsupervised machine learning algorithm to divide a dataset into pre-specified set of groups (known as clusters in this context). The algorithm assigned foods to clusters based on which assignments will keep the distance between the nutrient profile of each food assigned to a cluster and the mean nutrient profile for a given cluster as low as possible. In other words, it tries to assign foods to clusters that will achieve the highest possible intra-group similarity for the cluster number that we specified. To identify the optimal number of clusters, we used the silhouette method - which essentially compares the quality of clusters produced across a different range of cluster sizes. To make this comparison, the silhouette method calculates the average silhouette width for a given cluster size, *k*. The silhouette width is a measure of the average distance between clusters, where higher values are a sign of good clustering. 

The second approach we explored was using spectrum clustering. Spectrum clustering adds another step right before the k-means clustering approach. Instead of using the raw data to create clusters, spectrum clustering minimizes the number of variables that we cluster on by including a principal components analysis (also known as PCA) right before the clustering analysis. PCA may be especially advantageous when there are a large number of variables you want to cluster on, because it tries to linearly combine the old variables into new ones (aka PC scores) in a way that maximizes the variance. By maximizing variance during PCA, we can reduce the dimensions of the data without losing much information from the original data. Once we had the PC scores, we used the silhouette method like before to identify the optimal number of clusters before running k-means clustering.  

These were the two main clustering approaches that we compared. Since spectrum clustering combines the power of noise reduction through PCA with clustering analyses, we expected beforehand that it would be a better approach for grouping our data. For both sets of analyses we standardized the data beforehand, since all nutrient values are measured in different units. 

# Results

## Comparing k-means clustering to spectrum clustering 
### First approach: K means clustering 

The silhouette method recommended we use 2 clusters ([see appendix](#appendix)), so we ran k-means clustering using `kmeans()` with centers set to 2. Once created, we explored some of the characteristics of the clusters. First, there is a notable discrepancy in the number of foods assigned to each cluster, with the larger cluster consisting of `r max(data_mean_imp.kmeans$size)` and the smaller cluster consisting of `r min(data_mean_imp.kmeans$size)`. Ideally, the between-cluster sum of squares should be a large proportion of the total sum of squares (the total distance of all observations from the global center), which would suggest that there is high separation between groups. In this case, we find that between-cluster sum of squares (`r data_mean_imp.kmeans$betweenss`) explains `r data_mean_imp.kmeans$betweenss/data_mean_imp.kmeans$totss*100`% of the total sum of squares (`r data_mean_imp.kmeans$totss`). The plot below shows what the clusters looked like using k-means clustering across two randomly chosen variables: carbs and calories, along with the mean values of each cluster for those variables.

```{r}
clusterplot1
```

### Second approach: spectrum clustering 

To determine the number of PCs that would be most appropriate for our dataset, we created a scree plot with the proportion of variation explained (PVE) as a function of the number of PCs used ([see appendix](#appendix)). Based on the elbow rule, we were looking for a point on the plot at which there are diminishing returns on the PVE as PCs increase (i.e., there is a point at which the PVE flattens out as number of PCs increase). We chose to use 10 PCs based on the elbow rule. We then ran k-means clustering analysis on the 10 PCs that were created for each nutrient, with the recommended 8 clusters based on average silhouette width ([see appendix](#appendix)).

First, there is a wide range in the number of foods assigned to each cluster, with the largest cluster consisting of `r max(data_mean_imp.kmeans$size)` and the smallest cluster consisting of `r min(data_mean_imp.kmeans$size)`, and a median cluster size of `r median(data_mean_imp.kmeans$size)`. The between-cluster sum of squares (`r data_mean_imp.kmeans$betweenss`) explains `r data_mean_imp.kmeans$betweenss/data_mean_imp.kmeans$totss*100`% of the total sum of squares (`r data_mean_imp.kmeans$totss`). The plot below shows what the 8 clusters looked like using spectrum clustering across the first two PCs, along with labels for the centroid of each cluster. 

```{r}
clusterplot3
```

### Regular k-means clustering provides better clusters 

To compare the k-means and spectrum clustering methods on the quality of clusters they produced, we used different metrics of internal cluster validation to see if one method produced consistently superior clustering results compared to the other. Internal cluster validation is [one of three cluster validation statistics available](https://www.datanovia.com/en/lessons/cluster-validation-statistics-must-know-methods/) to evaluate the quality of cluster results. We chose internal cluster validation metrics because it best aligns with our goal of assessing cluster quality without using an external point of comparison, which would be considered external cluster validation (i.e., comparing whether the food groups we created actually align with the foods groups listed in the dataset). We are more interested in creating *new* high quality clusters using nutrient profiles, rather than trying to predict which of the previously established food groups a food would fall into based on its nutrient profile. 

The first internal validation metric we used is identical to the one we used to identify the optimal number of clusters before running our main clustering analyses: average silhouette width. The first plot below shows the silhouette width across the 2 clusters used for regular k-means clustering, while the second plot below shows the silhouette width across all 8 clusters used for spectrum clustering. Negative values would suggest that a food was placed in the wrong cluster. As shown in the plots, the average silhouette width for the regular k-means clustering (`r mean_ss`) is higher compared to that for the spectrum clustering (`r mean_ss1`),  providing tentative evidence that the regular k-means clustering provides better clusters compared to spectrum clustering.  

```{r}
plot_silhouette
```

```{r}
plot_silhouette1
```

To corroborate our findings, we compared the clustering results using a second internal validation metric known as the Dunn index. This metric essentially compares the inter-cluster separation to the intra-cluster compactness, where good clustering results would have a low diameter (i.e., they are highly compact) and a large distance between clusters (i.e., there is high separation). Thus, we want to maximize the Dunn index in our clustering analyses. In support of the previous evidence, the Dunn index is higher for the regular k-means clustering (`r km_stats$dunn`) compared to the spectrum clustering (`r km_stats1$dunn`). Overall, our results show that regular k-means clustering would provide a better grouping of foods compared to spectrum clustering, contrary to our a priori hypotheses. 

## Exploring "intelligent" clusters

To explore the "intelligent" clusters that we created through k-means clustering, we plotted words clouds of the most commonly used words within each cluster. For instance, the first word cloud shows that the most commonly used word in cluster 1 by far was “raw”, along with “frozen” “boiled” and “canned”. Thus, this cluster seems to be defined by *how* a food is stored or cooked. In terms of actual foods that are listed frequently in this cluster, "cereal" is relatively frequently used, along with other sugary foods.  

```{r}
knitr::include_graphics(here("figs", "wc1.png"))

```

On the other hand, the word cloud of the second cluster below shows that "raw" is also used frequently in this cluster. Importantly, a larger proportion of the foods in this cluster are related to meat and generally, high-protein foods (e.g., "meat", "lean", "fat", and "fish").

```{r}
knitr::include_graphics(here("figs", "wc2.png"))
```

We also explored which group had the highest calorie content, with cluster 2 having a noticeably larger calorie content compared to cluster 1. Thus, if someone was focusing specifically on reducing their overall calorie intake in their diet, it may be a good idea to avoid eating foods found in cluster 2. 

```{r}
kcal_cluster1
```

## Case study: Following a diet to gain muscle 

After determining the best clustering approach based on food nutrient profile, we provide a case study to serve as examples of how this tool can be used to make recommendations for a person who has specific dietary needs. Arnold is an aspiring professional bodybuilder that is interested in gaining muscle as quickly as possible. Since he knows the importance of nutrition in affecting the muscle-building process, he plans to change his diet to achieve this goal and has decided to follow the guidance he found at the links [here](https://www.coachmag.co.uk/nutrition/healthy-eating/1263/12-best-nutrients-and-vitamins-building-muscle-and-burning-fat) and [here](https://www.muscleandfitness.com/nutrition/gain-mass/10-nutrition-rules-follow-if-you-want-build-muscle/). Since Arnold is currently 180 pounds and a person that wants to gain muscle is recommended to consume 1.5 grams of protein per pound of bodyweight, his target daily intake of protein is 270 grams per day. It is also recommended that people consume between 2-3 grams of carbohydrates per pound to gain muscle. Therefore, Arnold aims to consume between 360 and 540 grams of total carbohydrates per day. Fat is another important macronutrient that will affect Arnold's muscle-building process. Since the articles he found suggest between 20 and 30 percent of his calories should come from fat, he aims to consume X grams of fat per day. Finally, it is recommended that he consume at least 3600 kilocalories per day to gain muscle. There are also several other nutrients that he would like to consume at above 2 standard deviations above the mean based on their muscle-building properties including: calcium, biotin, iron, vitamin C, selenium, Omega 3, Vitamin D, vitamin B12, copper, magnesium, riboflavin, and zinc. 

To simulate Arnold, we created a copy of the dataset from our main analyses and compared Arnold's daily nutrient targets to the daily nutrient recommendations for someone in the general population who matches him on all characteristics except for their level of activity. To determine a point of comparison for Arnold's nutrient intake, we used the [DRI Calculator for Healthcare Professionals from the National Argicultural Library](https://www.nal.usda.gov/fnic/dri-calculator/). This tool calculates daily nutrient recommendations based on the Dietary Reference Intakes (DRIs) established by the Health and Medicine Division of the National Academies of Sciences, Engineering and Medicine, representing the most current scientific knowledge on nutrient needs. We inserted gender (Male), age  (20), height (5 feet 10 inches), weight (180 pounds), and activity level (sedentary) for someone who matches Arnold on all characteristics *but* activity level, since Arnold will be above the mean on activity level compared to the typical person. Therefore, the nutrient recommendations provided by this tool are a representation of someone who matches Arnold on all characteristics, but does not aspire to be a pro bodybuilder like he does (and hence has a lower activity level). The metric of comparison we used is how much larger (or smaller) Arnold's nutrient goals are compared to the recommendations from the DRI Calculator. For instance, Arnold is aiming to consume 3600 kilocalories per day, while it is generally recommended to consume 2734 kilocalories per day for someone like him but is less active. Therefore, Arnold is consuming approximately 1.32 (3600/2734) times the amount of kilocalories recommended. Based on these calculations, Arnold will be consuming 1.2 times the amount of total carbohydrates recommended, 4.15 times the amount of total carbohydrates recommended, 270 times the amount of total saturated fats recommended, and 10.8 times the amount of total total fat recommended. We created nutrient data for Arnold by multiplying the average value of the target nutrient across the entire dataset by the amount Arnold is consuming above the mean (e.g., 1.32 * average value of nutrient across all foods) for kilocalories, total carbohydrates, saturated fats, protein, and total fat. On the other hand, for the list of nutrients above where Arnold generally knows he wants to consume at least 2 standard deviations above the mean (i.e., calcium, biotin, iron, vitamin C, selenium, Omega 3, Vitamin D, vitamin B12, copper, magnesium, riboflavin, and zinc), we calculated and inserted the value representing 2 standard deviations above the mean into Arnold's nutrient data. 

Next, we identified the cluster that most closely matched Arnold’s nutrient needs. That is, we identified the cluster that had the smallest euclidean distance from Arnold's goal nutrient profile. Based on our analyses, Arnold would best achieve his goals by eating foods in cluster 2. After identifying the cluster that Arnold best fit into, we identified the foods with the smallest euclidean distance from the center of cluster 2 in the original dataset to provide recommendations for the 10 top foods that meet Arnold's target nutrient profile. The table below shows clearly that Arnold should target meats and fish to achieve his goal of becoming a pro bodybuilder.  

```{r}
distances %>% arrange(distances) %>% slice_head(n = 10) %>%  rename(
    Food = wide_data.FoodDescription,
    Distance = distances
    ) %>% knitr::kable()
```


```{r, eval = F}
# calories

3600/2734

# carbs

450/mean(c(444,308))

# protein

270/65

# sat fat

mean(c(3600*(.05), 3600*(.1)))

# overall fat
# arnold is recommended to have 900 g of fat/day (avg of 20-30%)
3600*.25

900/mean(c(61, 106))
```

# Conclusion {#conclusion} 

Our results contradict our a priori hypothesis that spectrum clustering would provide much better groups of foods compared to k-means clustering. Using various metrics of internal clustering validation, we find that k-means clustering serves as a better method with this dataset for creating clusters. We explored the final set of clusters through various plots of the most frequently used words in each cluster, along with average calorie count per cluster. 

Our case study with Arnold provides an example of how these results can be used in a real-world context. Although we chose to focus on one specific example of the practical uses of this work, there are a number of other contexts that are relevant. For instance, these results can help patients of chronic illness identify groups of foods that help improve their medical condition. In another case, our results can be used to cluster new foods recently approved by the FDA based on their nutrient content, which may be helpful in grocery stores to determine food placement. On a more individual level, if a person likes a specific food for its nutrient content, they can use our clustering result to help them identify similar foods that they may enjoy. Finally, these results can be used when a person is following a recipe and wants to use a food from a specific cluster, but does not have that ingredient readily available. Using our clustering results, they can identify the foods that are most similar to a missing ingredient and replace it easily.


# Limitations {#limitations} 

One of the more notable limitations of this work is that the Canadian Nutrient File only provides average amounts of the nutrients for a combination of all available versions of a given food (e.g., average sugar content of all brands of ketchup). Therefore, it is possible that the clustering results here may not be useful in cases where the nutrient profile of a specific brand of food deviates far from the mean.
Also, this dataset is only relevant to products available in Canada - so the results cannot be generalized to products from other countries. Therefore, future research should explore whether these findings replicate among products in other countries. Another feature of the dataset that may be considered a limitation depending on a person's needs is that the nutrient values are all standardized and thus may not be representative of how much a person may actually consume in a package. A person would need to convert the nutrient values based on the actual portion sizes they eat if they wanted to accurately assess many of their daily nutrient goals their hitting. Finally, in the case study, we had only a proxy for nutrient recommendations based on target nutrient goals. More specifically, we used daily recommended nutrients as the proxy to scale Arnold's nutrient amounts when we created the fake data, but all of the nutrients in our dataset are at the level of an individual food. Therefore, using this tool with food-specific goals may be more appropriate, since our calculations were at a more aggregate level (i.e., "how much above the average are Arnold's nutrient goals?" rather than "how much above the average is this specific food?"). Overall, there are a number of fruitful avenues for future work to extend and improve upon our current analyses. 

# Appendix {#appendix} 


## Full summary of clean dataset {#clean-data-summary}

```{r, results = 'asis', cache = T}
data_mean_imp %>% dfSummary(.,  plain.ascii = FALSE, style = 'grid', graph.magnif = 0.75, 
          valid.col = FALSE, tmp.img.dir = "/tmp")

```

## Missing values in clean dataset {#missing-vals-clean}

```{r}
inspect.na(wide_data, summary = F)
```

## Optimal number of clusters for k-means clustering 

```{r}
silh_ID1
```

## Scree plot from PCA in spectrum clustering

```{r}
knitr::include_graphics(here("figs", "scree_p1.png"))
```


## Optimal number of clusters for spectrum clustering on 10 PCs

```{r}
silh_ID3
```


## List of packages used 

```{r, results = 'asis'}

report_packages()
```


## Citations for packages used 

```{r, results = 'asis'}
cite_packages()

```


# References


\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

